import subprocess
import requests
import threading
import queue
import time
import sys

# Field mapping consistent with PacketSchema in main.py
FIELDS = [
    "frame.time_epoch",
    "frame.protocols",
    "ip.src",
    "ip.dst",
    "ipv6.src",
    "ipv6.dst",
    "tcp.srcport",
    "tcp.dstport",
    "udp.srcport",
    "udp.dstport",
    "tcp.seq",
    "tcp.flags.syn",
    "tcp.flags.ack",
    "tcp.flags.fin",
    "tcp.flags.reset",
    "tcp.flags.push",
    "tcp.flags.urg",
    "tcp.analysis.retransmission",
    "tcp.window_size_value",
    "ip.ttl",
    "ipv6.hlim",
    "ip.flags.mf",
    "ipv6.fragment",
    "frame.len",
    "tcp.len",
    "udp.length",
    "_ws.col.info"
]

FIELD_MAP = [
    "timestamp", "protocols", "src_ip_v4", "dst_ip_v4", "src_ip_v6", "dst_ip_v6",
    "src_port_tcp", "dst_port_tcp", "src_port_udp", "dst_port_udp",
    "tcp_seq", "tcp_flags_syn", "tcp_flags_ack", "tcp_flags_fin",
    "tcp_flags_rst", "tcp_flags_psh", "tcp_flags_urg", "tcp_retransmission",
    "tcp_window_size", "ttl_hop_limit_v4", "ttl_hop_limit_v6",
    "ip_flags_mf", "ipv6_fragment", "packet_size", "payload_len_tcp",
    "payload_len_udp", "info"
]

API_URL = "http://localhost:9000/"
# Increased queue size to handle larger bursts
packet_queue = queue.Queue(maxsize=50000) 
NUM_WORKERS = 20

def sender_worker(worker_id):
    """Reads packets from the queue and sends them to the Pathway API using a persistent session."""
    session = requests.Session()
    # Adapter to allow more connections in the pool
    adapter = requests.adapters.HTTPAdapter(pool_connections=NUM_WORKERS, pool_maxsize=NUM_WORKERS)
    session.mount("http://", adapter)
    
    # print(f"Worker {worker_id} started.")
    
    while True:
        try:
            packet = packet_queue.get() 
            if packet is None: # Sentinel to stop
                break
                
            try:
                # Use session for connection pooling
                # Short timeout to fail fast if server is overloaded
                session.post(API_URL, json=packet, timeout=0.2)
            except requests.exceptions.RequestException:
                # In high-throughput scenarios, some drops are acceptable to keep fresh data coming
                pass
            finally:
                packet_queue.task_done()
                
        except Exception as e:
            print(f"Worker {worker_id} error: {e}", file=sys.stderr)

def monitor_worker():
    """Prints queue statistics periodically."""
    while True:
        time.sleep(3)
        q_size = packet_queue.qsize()
        if q_size > 100:
            print(f"[Monitor] Queue Size: {q_size} / {packet_queue.maxsize}")
        if q_size > 40000:
            print("[Monitor] WARNING: Queue near capacity! Packets may be dropped.")

def main():
    cmd = [
        "tshark", 
        "-i", "lo", 
        "-l", 
        "-f", "not port 9000 and not port 8011",
        "-T", "fields"
    ]
    for f in FIELDS:
        cmd.extend(["-e", f])

    print(f"Starting Sentinel Live Capture (Multi-threaded: {NUM_WORKERS} workers)...")
    print(f"Streaming packets to Pathway at {API_URL}")

    # Start worker threads
    workers = []
    for i in range(NUM_WORKERS):
        t = threading.Thread(target=sender_worker, args=(i,), daemon=True)
        t.start()
        workers.append(t)

    # Start monitor thread
    monitor = threading.Thread(target=monitor_worker, daemon=True)
    monitor.start()

    try:
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True
        )

        if process.stdout is None:
            print("Error: process.stdout is None")
            return

        for line in process.stdout:
            line = line.strip()
            if not line:
                continue

            vals = line.split("\t")

            if len(vals) < len(FIELD_MAP):
                vals += [""] * (len(FIELD_MAP) - len(vals))

            row = dict(zip(FIELD_MAP, vals))

            try:
                processed = {
                    "timestamp": float(row["timestamp"]) if row["timestamp"] else 0.0,
                    "protocols": row["protocols"],
                    "src_ip": row["src_ip_v4"] or row["src_ip_v6"],
                    "dst_ip": row["dst_ip_v4"] or row["dst_ip_v6"],
                    "src_port": row["src_port_tcp"] or row["src_port_udp"],
                    "dst_port": row["dst_port_tcp"] or row["dst_port_udp"],
                    "packet_size": row["packet_size"],
                    "payload_len": row["payload_len_tcp"] or row["payload_len_udp"] or "0",
                    "info": row["info"],
                    "tcp_seq": row["tcp_seq"] or "0",
                    "tcp_flags_syn": row["tcp_flags_syn"],
                    "tcp_flags_ack": row["tcp_flags_ack"],
                    "tcp_flags_fin": row["tcp_flags_fin"],
                    "tcp_flags_rst": row["tcp_flags_rst"],
                    "tcp_flags_psh": row["tcp_flags_psh"],
                    "tcp_flags_urg": row["tcp_flags_urg"],
                    "tcp_retransmission": row["tcp_retransmission"],
                    "tcp_window_size": row["tcp_window_size"] or "0",
                    "ttl_hop_limit": row["ttl_hop_limit_v4"] or row["ttl_hop_limit_v6"],
                    "fragmentation": "Yes" if (
                        row["ip_flags_mf"] == "1" or row["ipv6_fragment"]
                    ) else "No"
                }

                if processed["dst_port"] == "8055" or processed["src_port"] == "8055":
                    # Only print every 100th debug message to reduce console spam
                    pass 
                
                # Push to queue instead of blocking send
                try:
                    packet_queue.put_nowait(processed)
                except queue.Full:
                    # Drop packet if queue is full to prevent tshark blocking
                    # print("Queue full, dropping packet", file=sys.stderr)
                    pass

            except Exception:
                continue

    except KeyboardInterrupt:
        print("\nStopping Live Capture.")
        process.terminate()
        # Signal workers to stop
        for _ in range(NUM_WORKERS):
            packet_queue.put(None) 
            
    except Exception as e:
        print(f"Capture error: {e}")
        process.terminate()


if __name__ == "__main__":
    main()
